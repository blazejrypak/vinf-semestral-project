{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0747ce4-e6c2-4e58-9acd-3bd765f2fa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from pyspark.sql.types import *\n",
    "import pyspark \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from scrapy.http import TextResponse\n",
    "import re\n",
    "from pyspark.sql.functions import transform\n",
    "from utils import *\n",
    "import jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "544d3501-f2c6-4717-a868-5cc7c9f2b334",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.2.0-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/11/22 14:41:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.sparkContext._conf.getAll()\n",
    "conf = spark.sparkContext._conf.setAll([('spark.executor.memory', '2g'), ('spark.app.name', 'Aktuality Parser'), ('spark.executor.cores', '1'), ('spark.cores.max', '6'), ('spark.driver.memory','1g'), ('spark.executor.memory','2g')])\n",
    "spark.sparkContext.stop()\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2524e7a2-a049-44ed-b700-6c9f06a5eeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = []\n",
    "collection = None    \n",
    "part = 6\n",
    "if part == 1:\n",
    "    collection = iter(sorted(os.listdir('/home/jovyan/work/html_collection/'))[:5000])\n",
    "if part == 2:\n",
    "    collection = iter(sorted(os.listdir('/home/jovyan/work/html_collection/'))[5000:10000])\n",
    "if part == 3:\n",
    "    collection = iter(sorted(os.listdir('/home/jovyan/work/html_collection/'))[10000:15000])\n",
    "if part == 4:\n",
    "    collection = iter(sorted(os.listdir('/home/jovyan/work/html_collection/'))[15000:20000])\n",
    "if part == 5:\n",
    "    collection = iter(sorted(os.listdir('/home/jovyan/work/html_collection/'))[20000:25000])\n",
    "if part == 6:\n",
    "    collection = iter(sorted(os.listdir('/home/jovyan/work/html_collection/'))[25000:])\n",
    "for current_file_path in collection:\n",
    "    if '.json' in current_file_path:\n",
    "        with open('/home/jovyan/work/html_collection/' + current_file_path, encoding='utf-8') as json_file:\n",
    "            data = json.load(json_file)\n",
    "            articles.append((current_file_path, data['url'], data['article_html_body']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3810ea52-c83a-45f8-80dc-ce47ebd32e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list to RDD\n",
    "rdd = spark.sparkContext.parallelize(articles, numSlices=(len(articles)))\n",
    "del articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89635237-cf8e-4ab9-b6e9-cd0a19f262c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################\n",
    "# ##################################################\n",
    "# ##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4fe2412-4f8b-465e-8ce0-65e772954ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_article(file_name, url, article_html_body):\n",
    "    response = TextResponse(url=url, body=article_html_body, encoding='utf-8')\n",
    "    title = response.css('#article > div.article-headline-wrapper > h1').xpath('//h1/span/text()').get()\n",
    "    article_body = response.css('.fulltext')\n",
    "    article_content = ''\n",
    "    for p in article_body.css('p::text').getall():\n",
    "        article_content += re.sub('\\s+', ' ', str(p)) + ' '\n",
    "    result = {\n",
    "        \"url\": url,\n",
    "        \"title\": '',\n",
    "        \"body\": article_content\n",
    "    }\n",
    "    if title:\n",
    "        result['title'] = title\n",
    "    return (file_name.replace('.json', ''), result['url'], result['title'], result['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7d1ad12-133e-4afb-b413-15bf5a402667",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2 = rdd.map(lambda x: parse_article(x[0], x[1], x[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d1765d6-d2a6-4d29-b282-2f7b0382a11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdd2.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9d1529c-ca33-4afa-a9de-48ce3e44c033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdd3 = rdd2.map(lambda x: (x[0], x[1], prepare_text(x[2]), prepare_text(x[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "367ccf2f-bea3-4615-8ae6-a3b35c5ee9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdd3.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "252d994b-e700-45c5-89c7-c1eb8bcd069b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_persons(file_name, text):\n",
    "    person_entities = []\n",
    "    for name_ in slovak_first_names:\n",
    "        name = str2ascii(name_)\n",
    "        reg_pat = f\"((?:{name})(?: [A-Z][a-z]+)+)\"\n",
    "        names_with_first_name = regex.findall(reg_pat, text)\n",
    "        person_entities.extend(names_with_first_name)\n",
    "    return (file_name , person_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0347ce56-c526-46a9-9e23-2246d26a1dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd4 = rdd2.map(lambda x: get_persons(x[0], x[2] + '\\n' + x[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "488c9090-4ab1-4808-b457-c0f4508c1879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdd4.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d5fe31bb-2c63-4c27-870d-b150a59d5715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_companies(file_name, text):\n",
    "    _found_companies = []\n",
    "    companies_suffixes = \"(?:s\\.r\\.o|a\\.s\\.|j\\. a\\. s\\.|akc\\. spol\\.|spol\\. s\\. r\\. o\\.|s\\. r\\. o\\.|ver\\. obch\\. spol\\.|v\\. o\\. s\\.|kom\\. spol\\.|k\\. s\\.|Å¡\\. p\\.|Inc|Ltd|Jr|Sr|Co)\"\n",
    "    pattern = f\"((?:[A-Z][a-z]+)(?: [A-Z][a-z]+)* {companies_suffixes})\"\n",
    "    found_companies = regex.findall(pattern, text)\n",
    "    _found_companies.extend(found_companies)\n",
    "    return (file_name, _found_companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e9b03734-efa4-43cd-90eb-6864c19436ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd5 = rdd2.map(lambda x: get_companies(x[0], x[2] + '\\n' + x[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b30d7069-040e-4141-bac9-a7f65b58fa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "entitySchema = StructType([       \n",
    "    StructField(\"file_name\", StringType(), True),\n",
    "    \n",
    "    StructField(\"entity\", ArrayType(StringType()), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "83067139-e4a6-47b7-a65e-f7a183ee4de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "DF_companies = spark.createDataFrame(rdd5, schema = entitySchema)\n",
    "DF_companies.write.mode('overwrite').json(f'companies_output_part_{part}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "840e13c3-c02c-4fbe-b7eb-9c5c3c8de7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "DF_companies = spark.createDataFrame(rdd4, schema = entitySchema)\n",
    "DF_companies.write.mode('overwrite').json(f'entity_names_output_part_{part}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c7751b-5776-4b5f-b0bd-afba5a2b07af",
   "metadata": {},
   "outputs": [],
   "source": [
    "entityArticleSchema = StructType([       \n",
    "    StructField(\"file_name\", StringType(), True),\n",
    "    StructField(\"url\", StringType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"content\", StringType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29435984-a7dd-4827-bf50-79f1e8004bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_companies = spark.createDataFrame(rdd2, schema = entityArticleSchema)\n",
    "DF_companies.write.mode('overwrite').json(f'articles_output_part_{part}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
